{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Snorkel\n",
    "from snorkel.labeling import LabelingFunction\n",
    "import re\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from snorkel.labeling import labeling_function\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "punc = string.punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "nltk.download('stopwords')\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "import spacy\n",
    "\n",
    "#Tensorflow and Keras ML model libraries\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date headline_category  \\\n",
       "0      20010102           unknown   \n",
       "1      20010102           unknown   \n",
       "2      20010102           unknown   \n",
       "3      20010102           unknown   \n",
       "4      20010102           unknown   \n",
       "\n",
       "                                       headline_text  \n",
       "0  Status quo will not be disturbed at Ayodhya; s...  \n",
       "1                Fissures in Hurriyat over Pak visit  \n",
       "2              America's unwanted heading for India?  \n",
       "3                 For bigwigs; it is destination Goa  \n",
       "4               Extra buses to clear tourist traffic  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../india-news-headlines.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650970, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unknown', 'entertainment.hindi.bollywood', 'india', ...,\n",
       "       'sports.football.euro-2021', 'business.markets.ipo',\n",
       "       'sports.tokyo-olympics.india-in-tokyo'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### conduct an NLTK analysis on the mostp popular words in the dataset to categorise if they are positive or negative words.\n",
    "### additionally categorise by sports category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  Status quo will not be disturbed at Ayodhya; s...\n",
       "1                Fissures in Hurriyat over Pak visit\n",
       "2              America's unwanted heading for India?\n",
       "3                 For bigwigs; it is destination Goa\n",
       "4               Extra buses to clear tourist traffic"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['publish_date', 'headline_category'], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Snorkel for the labelling of headlines with classes of positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 1\n",
    "neg = 0\n",
    "#neural\n",
    "neu = -1\n",
    "\n",
    "# function that inputs words to represent a label\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.headline_text.lower() for word in keywords):\n",
    "        return label\n",
    "    return neu\n",
    "\n",
    "#function for correctly assigning a label\n",
    "def make_keyword(keywords, label):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I asked chat GPT to produce words for both positive and negative words that may be found within an article\n",
    "\n",
    "# Positive words\n",
    "# positive_words = [\"inspiring\",\"motivating\",\"encouraging\",\"empowering\",\"enriching\",\"fulfilling\",\"joyful\",\"uplifting\",\"heartwarming\",\n",
    "#     \"exciting\",\"optimistic\",\"radiant\",\"hopeful\",\"refreshing\",\"transformative\",\"grateful\",\"compassionate\",\"respectful\",\"honest\",\n",
    "#     \"supportive\",\"friendly\",\"amicable\",\"cheerful\",\"energetic\",\"passionate\",\"confident\",\"creative\",\"enthusiastic\",\"dynamic\",\"courageous\",\n",
    "#     \"adventurous\",\"fearless\",\"bold\",\"brave\",\"determined\",\"ambitious\",\"successful\",\"accomplished\",\"triumphant\",\"victorious\",\"celebrated\",\n",
    "#     \"esteemed\",\"honored\",\"proud\",\"satisfied\",\"content\",\"joyous\",\"blissful\",\"ecstatic\",\"radiant\",\"gracious\",\"generous\",\"kind\",\"compassionate\",\n",
    "#     \"understanding\",\"accepting\",\"appreciative\",\"respectful\",\"patient\",\"forgiving\",\"calm\",\"serene\",\"tranquil\",\"relaxed\",\"peaceful\",\n",
    "#     \"harmonious\",\"balanced\",\"healthy\",\"vibrant\",\"invigorated\",\"rejuvenated\",\"energetic\",\"alive\",\"connected\",\"engaged\",\"inspirational\",\n",
    "#     \"uplifting\",\"motivational\",\"encouraging\",\"supportive\",\"nurturing\",\"affirming\",\"reassuring\",\"hopeful\",\"optimistic\",\"confident\",\n",
    "#     \"secure\",\"empowered\",\"enlightened\",\"aware\",\"mindful\",\"grateful\",\"thankful\",\"appreciative\"]\n",
    "\n",
    "positive_words = ['achieve', 'advantage', 'affirm', 'aid', 'aim', 'alive', 'amazing', 'approve', 'ascend', 'assure', \n",
    "                  'astonishing', 'attract', 'award', 'benefit', 'best', 'better', 'bliss', 'boost', 'brave', 'breakthrough', \n",
    "                  'bright', 'brilliant', 'celebrate', 'champion', 'cheer', 'clever', 'commend', 'complete', 'congratulate', \n",
    "                  'conquer', 'convince', 'courage', 'creative', 'cure', 'dazzling', 'delight', 'deliver', 'deserve', 'destiny', \n",
    "                  'discover', 'ease', 'effective', 'efficient', 'elated', 'empower', 'encourage', 'enjoy', 'enlighten', 'enterprising', \n",
    "                  'enthusiasm', 'excellent', 'excite', 'exhilarating', 'expand', 'explore', 'fabulous', 'fair', 'famous', \n",
    "                  'fantastic', 'fascinating', 'favor', 'flourish', 'fortunate', 'free', 'fresh', 'friendly', 'fulfill', 'fun', \n",
    "                  'gain', 'generous', 'gift', 'glad', 'glamorous', 'glory', 'good', 'gorgeous', 'grace', 'gracious', 'grand', \n",
    "                  'grateful', 'great', 'grow', 'handsome', 'happy', 'harmony', 'heal', 'healthy', 'heavenly', 'helpful', \n",
    "                  'hero', 'high', 'honor', 'hope', 'hot', 'hug', 'illuminate', 'imagine', 'improve', 'incredible', 'innovate', \n",
    "                  'inspire', 'intelligent', 'invent', 'joy', 'jubilant', 'justice', 'keen', 'kind', 'laugh', 'lavish', \n",
    "                  'lead', 'legendary', 'liberate', 'light', 'like', 'lionhearted', 'lively', 'love', 'loyal', 'lucky', 'magic', \n",
    "                  'magnificent', 'marvelous', 'master', 'medal', 'mend', 'merit', 'miracle', 'motivate', 'natural', 'nice', \n",
    "                  'noble', 'nourish', 'optimal', 'outstanding', 'overcome', 'paradise', 'passion', 'peace', 'perfect', \n",
    "                  'pleasant', 'pleased', 'pleasure', 'popular', 'positive', 'power', 'praise', 'precious', 'premium', 'pretty', \n",
    "                  'pride', 'prize', 'prosper', 'proud', 'quality', 'quick', 'radiant', 'ready', 'reassure', 'recharge', \n",
    "                  'refresh', 'rejoice', 'relax', 'relief', 'remarkable', 'renew', 'renowned', 'rescue', 'resilient', \n",
    "                  'restore', 'revel', 'reward', 'rich', 'right', 'robust', 'satisfy', 'secure', 'shine', 'smile', 'smooth', \n",
    "                  'soulful', 'spark', 'spectacular', 'splendid', 'sprout', 'stellar', 'strength']\n",
    "\n",
    "# Negative words\n",
    "# negative_words = [\"disappointing\",\"frustrating\",\"discouraging\",\"upsetting\",\"unfortunate\",\"sad\",\"heartbreaking\",\n",
    "#     \"tragic\",\"painful\",\"hurtful\",\"offensive\",\"insulting\",\"insensitive\",\"harmful\",\"damaging\",\"destructive\",\"terrible\",\"horrible\",\n",
    "#     \"awful\",\"miserable\",\"depressing\",\"desperate\",\"hopeless\",\"dismal\",\"gloomy\",\"melancholy\", \"sadness\",\"sorrow\",\"anguish\",\"agony\",\n",
    "#     \"misery\",\"pessimistic\",\"cynical\",\"skeptical\",\"suspicious\",\"disbelieving\",\"doubtful\",\"unbelievable\",\"displeased\",\"unsatisfied\",\n",
    "#     \"unhappy\",\"dissatisfied\",\"angry\",\"furious\",\"enraged\",\"infuriated\",\"annoyed\",\"irritated\",\"frustrated\",\"exasperated\",\"stressed\",\n",
    "#     \"Anxious\",\"Nervous\",\"Tense\",\"Worried\",\"Fearful\",\"Afraid\",\"Scared\",\"Terrified\",\"Panicked\",\"Despair\",\"Despondent\",\"Defeated\",\n",
    "#     \"Surrendered\",\"Powerless\",\"Inferior\",\"Inadequate\",\"Unimportant\",\"Worthless\",\"Insignificant\",\"Unworthy\",\"Ashamed\",\"Embarrassed\",\n",
    "#     \"Guilty\",\"Remorseful\",\"Regretful\",\"Mortified\",\"Humiliated\",\"Disgusted\",\"Repulsed\",\"Revolted\",\"Nauseated\",\"Appalled\",\"Horrified\",\n",
    "#     \"Offended\",\"Resentful\",\"Bitter\",\"Hostile\",\"Vengeful\",\"Hateful\",\"Malicious\", \"War\", 'Killed', 'Death', ]\n",
    "negative_words = ['accused', 'attack', 'ban', 'bankrupt', 'beware', 'blame', 'bleak', 'block', 'bloodbath', 'bomb', \n",
    "                  'breakdown', 'bribe', 'burden', 'bust', 'catastrophe', 'chaos', 'charge', 'clash', 'collapse', 'concerns',\n",
    "                  'controversy', 'crackdown', 'crisis', 'crumble', 'cut', 'damage', 'death', 'debt', 'defeat', 'deficit',\n",
    "                  'delay', 'demand', 'demonstrate', 'denounce', 'depressed', 'desperate', 'deteriorating', 'disagree', 'disappoint',\n",
    "                  'disarray', 'disastrous', 'disclose', 'dismiss', 'dispute', 'dissolve', 'disturbance', 'doubt', 'downturn', \n",
    "                  'drag', 'drop', 'embarrassment', 'emergency', 'endanger', 'entangled', 'evict', 'expose', 'fail', 'fall',\n",
    "                  'fault', 'fear', 'fiasco', 'fight', 'fire', 'flaw', 'flee', 'flood', 'forced', 'fraud', 'freeze', 'frustrate',\n",
    "                  'fury', 'harm', 'havoc', 'hit', 'horrify', 'hostile', 'hurt', 'hype', 'implode', 'inflation', 'injure', 'insult',\n",
    "                  'interfere', 'interruption', 'invade', 'investigation', 'jeopardy', 'kick', 'kill', 'lawsuit', 'leak', 'lose',\n",
    "                  'meltdown', 'mistake', 'nervous', 'nuisance', 'outrage', 'overrule', 'pain', 'panic', 'penalty', 'peril',\n",
    "                  'poison', 'pollute', 'pressure', 'probe', 'punish', 'quarrel', 'question', 'quit', 'rally', 'rampage', 'reject',\n",
    "                  'resign', 'restrict', 'retaliate', 'retreat', 'revolt', 'ridicule', 'rip', 'risk', 'rough', 'ruin', 'rupture', \n",
    "                  'scandal', 'scold', 'scorch', 'scorn', 'scream', 'seize', 'sever', 'shame', 'shatter', 'shock', 'shutdown',\n",
    "                  'slump', 'smash', 'smuggle', 'spoil', 'spurn', 'stain', 'stall', 'strike', 'struggle', 'sue', 'suffer',   \n",
    "                  'suspend', 'taint', 'terminate', 'terrorize', 'threat', 'thwart', 'torture', 'tragedy', 'trap', 'trespass', \n",
    "                  'trouble', 'unrest', 'upheaval', 'upset', 'vandalize', 'violate', 'warning', 'weaken', 'worsen', 'wound']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  I will now add these words to the make keyword function\n",
    "positive_keyword = make_keyword(keywords=positive_words, label=pos)\n",
    "negative_keyword = make_keyword(keywords=negative_words, label=neg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use the TextBlob library to determine the polarity and subjectivity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.headline_text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "#find polarity\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return pos if x.polarity > 0.6 else neu\n",
    "    # if x.polarity > 0.1:\n",
    "    #     return pos\n",
    "    # elif x.polarity < -0.1:\n",
    "    #     return neg\n",
    "    # else:\n",
    "    #     return neu\n",
    "#find subjectivity \n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return pos if x.subjectivity >= 0.5 else neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3650970/3650970 [5:16:59<00:00, 191.96it/s]   \n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.026]\n",
      "  1%|          | 1/100 [00:00<00:17,  5.55epoch/s]INFO:root:[10 epochs]: TRAIN:[loss=0.009]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.001]\n",
      " 23%|██▎       | 23/100 [00:00<00:00, 99.71epoch/s]INFO:root:[30 epochs]: TRAIN:[loss=0.002]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.001]\n",
      " 45%|████▌     | 45/100 [00:00<00:00, 145.45epoch/s]INFO:root:[50 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[60 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[70 epochs]: TRAIN:[loss=0.001]\n",
      " 71%|███████   | 71/100 [00:00<00:00, 179.09epoch/s]INFO:root:[80 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[90 epochs]: TRAIN:[loss=0.001]\n",
      "100%|██████████| 100/100 [00:00<00:00, 161.79epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "#combine all the labeling functions \n",
    "lfs = [positive_keyword, negative_keyword, textblob_polarity, textblob_subjectivity]\n",
    "#apply the lfs on the dataframe\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_snorkel = applier.apply(df=df)\n",
    "#apply the label model\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "#fit on the data\n",
    "label_model.fit(L_snorkel)\n",
    "#predict and create the labels\n",
    "df[\"label\"] = label_model.predict(L=L_snorkel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1861021\n",
       " 1    1162856\n",
       " 0     627093\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1162856\n",
       "0     627093\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering out unlabeled data points\n",
    "df= df.loc[df.label.isin([0,1]), :]\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "For the modelling side of the project I will use Tensor Flow and Keras to produce a Neural Network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: WORKING ON THIS STAGE ONWARDS, BELOW IS NOT MY FINAL CODE, JUST TESTING THIS CODE OUT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I will train and test split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_8828\\1869780026.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tokenized_text = [[nlp(i.lower().strip())] for i in tqdm(raw_text)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a60a976806448de9a8afa1c0ebf10f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1789949 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m     28\u001b[0m \u001b[39m#apply the data preprocessing function\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m data \u001b[39m=\u001b[39m  preparation_text_data(data)\n",
      "Cell \u001b[1;32mIn[35], line 17\u001b[0m, in \u001b[0;36mpreparation_text_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     15\u001b[0m raw_text \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mheadline_text\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     16\u001b[0m \u001b[39m# tokenize\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m tokenized_text \u001b[39m=\u001b[39m [[nlp(i\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mstrip())] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(raw_text)]\n\u001b[0;32m     18\u001b[0m \u001b[39m#define the punctuations and stop words\u001b[39;00m\n\u001b[0;32m     19\u001b[0m punc \u001b[39m=\u001b[39m string\u001b[39m.\u001b[39mpunctuation \n",
      "Cell \u001b[1;32mIn[35], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     15\u001b[0m raw_text \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mheadline_text\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     16\u001b[0m \u001b[39m# tokenize\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m tokenized_text \u001b[39m=\u001b[39m [[nlp(i\u001b[39m.\u001b[39;49mlower()\u001b[39m.\u001b[39;49mstrip())] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(raw_text)]\n\u001b[0;32m     18\u001b[0m \u001b[39m#define the punctuations and stop words\u001b[39;00m\n\u001b[0;32m     19\u001b[0m punc \u001b[39m=\u001b[39m string\u001b[39m.\u001b[39mpunctuation \n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:1026\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1025\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1026\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1028\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:253\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:274\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\ml\\tb_framework.py:33\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 33\u001b[0m     step_model \u001b[39m=\u001b[39m ParserStepModel(\n\u001b[0;32m     34\u001b[0m         X,\n\u001b[0;32m     35\u001b[0m         model\u001b[39m.\u001b[39;49mlayers,\n\u001b[0;32m     36\u001b[0m         unseen_classes\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39munseen_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     37\u001b[0m         train\u001b[39m=\u001b[39;49mis_train,\n\u001b[0;32m     38\u001b[0m         has_upper\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39mhas_upper\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     39\u001b[0m     )\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m step_model, step_model\u001b[39m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:213\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\with_array.py:38\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\with_array.py:73\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     71\u001b[0m lengths \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[0;32m     72\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[1;32m---> 73\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[0;32m     76\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\maxout.py:53\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     51\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape2f(W, nO \u001b[39m*\u001b[39m nP, nI)\n\u001b[1;32m---> 53\u001b[0m Y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mgemm(X, W, trans2\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     54\u001b[0m Y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape1f(b, nO \u001b[39m*\u001b[39m nP)\n\u001b[0;32m     55\u001b[0m Z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape3f(Y, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nO, nP)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#make a copy of the dataframe\n",
    "data = df.copy()\n",
    "#define a function which handles the text preprocessing \n",
    "def preparation_text_data(data):\n",
    "    \"\"\"\n",
    "    This pipeline prepares the text data, conducting the following steps:\n",
    "    1) Tokenization\n",
    "    2) Lemmatization\n",
    "    4) Removal of stopwords\n",
    "    5) Removal of punctuation\n",
    "    \"\"\"\n",
    "    # initialize spacy object\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    # select raw text\n",
    "    raw_text = data.headline_text.values.tolist()\n",
    "    # tokenize\n",
    "    tokenized_text = [[nlp(i.lower().strip())] for i in tqdm(raw_text)]\n",
    "    #define the punctuations and stop words\n",
    "    punc = string.punctuation \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #lemmatize, remove stopwords and punctuationd\n",
    "    corpus = []\n",
    "    for doc in tqdm(tokenized_text):\n",
    "        corpus.append([word.lemma_ for word in doc[0] if (word.lemma_ not in stop_words and word.lemma_ not in punc)])\n",
    "    # add prepared data to df\n",
    "    data[\"headline_text\"] = corpus\n",
    "    return data\n",
    "#apply the data preprocessing function\n",
    "data =  preparation_text_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_representation(data):\n",
    "  tfidf_vect = TfidfVectorizer()\n",
    "  data['headline_text'] = data['headline_text'].apply(lambda text: \" \".join(set(text)))\n",
    "  X_tfidf = tfidf_vect.fit_transform(data['headline_text'])\n",
    "  print(X_tfidf.shape)\n",
    "  print(tfidf_vect.get_feature_names())\n",
    "  X_tfidf = pd.DataFrame(X_tfidf.toarray())\n",
    "  return X_tfidf\n",
    "#apply the TFIDV function\n",
    "X_tfidf = text_representation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X_tfidf\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#fit Log Regression Model\n",
    "clf= LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [\"The US imposes sanctions on Rassia because of the Ukranian war\"]\n",
    "tf = TfidfVectorizer()\n",
    "tfdf = tf.fit_transform(data['text'])\n",
    "vect = pd.DataFrame(tf.transform(new_data).toarray())\n",
    "new_data = pd.DataFrame(vect)\n",
    "logistic_prediction = clf.predict(new_data)\n",
    "print(logistic_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
