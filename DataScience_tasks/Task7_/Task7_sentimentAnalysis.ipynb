{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Snorkel\n",
    "from snorkel.labeling import LabelingFunction\n",
    "import re\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from snorkel.labeling import labeling_function\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "punc = string.punctuation\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "#Tensorflow and Keras ML model libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date headline_category  \\\n",
       "0      20010102           unknown   \n",
       "1      20010102           unknown   \n",
       "2      20010102           unknown   \n",
       "3      20010102           unknown   \n",
       "4      20010102           unknown   \n",
       "\n",
       "                                       headline_text  \n",
       "0  Status quo will not be disturbed at Ayodhya; s...  \n",
       "1                Fissures in Hurriyat over Pak visit  \n",
       "2              America's unwanted heading for India?  \n",
       "3                 For bigwigs; it is destination Goa  \n",
       "4               Extra buses to clear tourist traffic  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('india-news-headlines.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unknown', 'entertainment.hindi.bollywood', 'india', ...,\n",
       "       'sports.football.euro-2021', 'business.markets.ipo',\n",
       "       'sports.tokyo-olympics.india-in-tokyo'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  Status quo will not be disturbed at Ayodhya; s...\n",
       "1                Fissures in Hurriyat over Pak visit\n",
       "2              America's unwanted heading for India?\n",
       "3                 For bigwigs; it is destination Goa\n",
       "4               Extra buses to clear tourist traffic"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['publish_date', 'headline_category'], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Snorkel for the labelling of headlines with classes of positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 1\n",
    "neg = 0\n",
    "#neural\n",
    "neu = -1\n",
    "\n",
    "# function that inputs words to represent a label\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.headline_text.lower() for word in keywords):\n",
    "        return label\n",
    "    return neu\n",
    "\n",
    "#function for correctly assigning a label\n",
    "def make_keyword(keywords, label):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I asked chat GPT to produce words for both positive and negative words that may be found within an article\n",
    "\n",
    "# Positive words\n",
    "positive_words = [\"Inspiring\",\"Motivating\",\"Encouraging\",\"Empowering\",\"Enriching\",\"Fulfilling\",\"Joyful\",\"Uplifting\",\"Heartwarming\",\n",
    "    \"Exciting\",\"Optimistic\",\"Radiant\",\"Hopeful\",\"Refreshing\",\"Transformative\",\"Grateful\",\"Compassionate\",\"Respectful\",\"Honest\",\n",
    "    \"Supportive\",\"Friendly\",\"Amicable\",\"Cheerful\",\"Energetic\",\"Passionate\",\"Confident\",\"Creative\",\"Enthusiastic\",\"Dynamic\",\"Courageous\",\n",
    "    \"Adventurous\",\"Fearless\",\"Bold\",\"Brave\",\"Determined\",\"Ambitious\",\"Successful\",\"Accomplished\",\"Triumphant\",\"Victorious\",\"Celebrated\",\n",
    "    \"Esteemed\",\"Honored\",\"Proud\",\"Satisfied\",\"Content\",\"Joyous\",\"Blissful\",\"Ecstatic\",\"Radiant\",\"Gracious\",\"Generous\",\"Kind\",\"Compassionate\",\n",
    "    \"Understanding\",\"Accepting\",\"Appreciative\",\"Respectful\",\"Patient\",\"Forgiving\",\"Calm\",\"Serene\",\"Tranquil\",\"Relaxed\",\"Peaceful\",\n",
    "    \"Harmonious\",\"Balanced\",\"Healthy\",\"Vibrant\",\"Invigorated\",\"Rejuvenated\",\"Energetic\",\"Alive\",\"Connected\",\"Engaged\",\"Inspirational\",\n",
    "    \"Uplifting\",\"Motivational\",\"Encouraging\",\"Supportive\",\"Nurturing\",\"Affirming\",\"Reassuring\",\"Hopeful\",\"Optimistic\",\"Confident\",\n",
    "    \"Secure\",\"Empowered\",\"Enlightened\",\"Aware\",\"Mindful\",\"Grateful\",\"Thankful\",\"Appreciative\"]\n",
    "# Negative words\n",
    "negative_words = [\"Disappointing\",\"Frustrating\",\"Discouraging\",\"Upsetting\",\"Unfortunate\",\"Sad\",\"Heartbreaking\",\n",
    "    \"Tragic\",\"Painful\",\"Hurtful\",\"Offensive\",\"Insulting\",\"Insensitive\",\"Harmful\",\"Damaging\",\"Destructive\",\"Terrible\",\"Horrible\",\n",
    "    \"Awful\",\"Miserable\",\"Depressing\",\"Desperate\",\"Hopeless\",\"Dismal\",\"Gloomy\",\"Melancholy\", \"Sadness\",\"Sorrow\",\"Anguish\",\"Agony\",\n",
    "    \"Misery\",\"Pessimistic\",\"Cynical\",\"Skeptical\",\"Suspicious\",\"Disbelieving\",\"Doubtful\",\"Unbelievable\",\"Displeased\",\"Unsatisfied\",\n",
    "    \"Unhappy\",\"Dissatisfied\",\"Angry\",\"Furious\",\"Enraged\",\"Infuriated\",\"Annoyed\",\"Irritated\",\"Frustrated\",\"Exasperated\",\"Stressed\",\n",
    "    \"Anxious\",\"Nervous\",\"Tense\",\"Worried\",\"Fearful\",\"Afraid\",\"Scared\",\"Terrified\",\"Panicked\",\"Despair\",\"Despondent\",\"Defeated\",\n",
    "    \"Surrendered\",\"Powerless\",\"Inferior\",\"Inadequate\",\"Unimportant\",\"Worthless\",\"Insignificant\",\"Unworthy\",\"Ashamed\",\"Embarrassed\",\n",
    "    \"Guilty\",\"Remorseful\",\"Regretful\",\"Mortified\",\"Humiliated\",\"Disgusted\",\"Repulsed\",\"Revolted\",\"Nauseated\",\"Appalled\",\"Horrified\",\n",
    "    \"Offended\",\"Resentful\",\"Bitter\",\"Hostile\",\"Vengeful\",\"Hateful\",\"Malicious\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  I will now add these words to the make keyword function\n",
    "positive_keyword = make_keyword(keywords=positive_words, label=pos)\n",
    "negative_keyword = make_keyword(keywords=negative_words, label=neg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use the TextBlob library to determine the polarity and subjectivity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.headline_text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "#find polarity\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return pos if x.polarity > 0.6 else neu\n",
    "#find subjectivity \n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return pos if x.subjectivity >= 0.5 else neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the labeling functions \n",
    "lfs = [positive_keyword, negative_keyword, textblob_polarity, textblob_subjectivity ]\n",
    "#apply the lfs on the dataframe\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_snorkel = applier.apply(df=df)\n",
    "#apply the label model\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "#fit on the data\n",
    "label_model.fit(L_snorkel)\n",
    "#predict and create the labels\n",
    "df[\"label\"] = label_model.predict(L=L_snorkel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
